{
  "hash": "faf81490619d04d8b160b4acd1f89c84",
  "result": {
    "markdown": "---\ntitle: \"Machine Learning Exercise\" \noutput: html\neditor: visual\n---\n\n\n### Install Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\n#install.packages(\"ggplot2\")\nlibrary(ggplot2)\nlibrary(here)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nhere() starts at C:/Users/mn27712/MADA_NEW/muhammadnasir-mada2025-portofolio\n```\n:::\n\n```{.r .cell-code}\n#install.packages(\"patchwork\")  # This package is to redefine \"/\" operator for plot arrangement\nlibrary(patchwork)\n#install.packages(\"writexl\")\nlibrary(writexl)\nlibrary(haven)\n#install.packages(\"ggforce\")\nlibrary(ggforce)\n#install.packages(\"dplyr\")\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(lubridate)\n#install.packages(\"ggridges\") \nlibrary(ggridges)  #\nlibrary(forcats)\n#install.packages(\"gt\")\nlibrary(gt)\n#install.packages(\"gtExtras\", dependencies = TRUE)\nlibrary(gtExtras)\n#install.packages(\"gtsummary\")\nlibrary(gtsummary)   \n#install.packages(\"cli\")\nlibrary(cli)\n#install.packages(\"tidymodels\")\nlibrary(tidymodels)  # for the parsnip package, along with the rest of tidymodels\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n```\n:::\n\n```{.r .cell-code}\n#install.packages(\"broom.mixed\")\nlibrary(broom.mixed) # for converting bayesian models to tidy tibbles\n#install.packages(\"dotwhisker\")\nlibrary(dotwhisker)  # for visualizing regression results\n#install.packages(\"ggcorrplot\")\nlibrary(ggcorrplot)\n#install.packages(\"corrplot\")\nlibrary(corrplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ncorrplot 0.95 loaded\n```\n:::\n\n```{.r .cell-code}\n#install.packages(\"ggpubr\")# combine plot\n# Load the library\nlibrary(ggpubr)\n\n\n#install.packages(\"rsample\")\n#install.packages(\"purrr\")\nlibrary(rsample)\nlibrary(purrr)\n#install.packages(\"glmnet\")\nlibrary(glmnet)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-8\n```\n:::\n\n```{.r .cell-code}\n#install.packages(\"ranger\")\n\nlibrary(ranger)\n\n#install.packages(\"GGally\")\nlibrary(GGally)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n```\n:::\n:::\n\n\n### Read the dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#setting up the seed\nrngseed <- 1234\n\n\n# Load the dataset\ndata_loc <- here(\"machine-learning\", \"data\", \"df.rds\") \ndata <- readRDS(data_loc)\n\n\n\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n      Y  DOSE   AGE SEX   RACE     WT    HT\n  <dbl> <dbl> <dbl> <fct> <fct> <dbl> <dbl>\n1 2691.    25    42 1     2      94.3  1.77\n2 2639.    25    24 1     2      80.4  1.76\n3 2150.    25    31 1     1      71.8  1.81\n4 1789.    25    46 2     1      77.4  1.65\n5 3126.    25    41 2     2      64.3  1.56\n6 2337.    25    27 1     2      74.1  1.83\n```\n:::\n\n```{.r .cell-code}\ndim(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 120   7\n```\n:::\n\n```{.r .cell-code}\ncolnames(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Y\"    \"DOSE\" \"AGE\"  \"SEX\"  \"RACE\" \"WT\"   \"HT\"  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Y               DOSE            AGE        SEX     RACE   \n Min.   : 826.4   Min.   :25.00   Min.   :18.00   1:104   1 :74  \n 1st Qu.:1700.5   1st Qu.:25.00   1st Qu.:26.00   2: 16   2 :36  \n Median :2349.1   Median :37.50   Median :31.00           7 : 2  \n Mean   :2445.4   Mean   :36.46   Mean   :33.00           88: 8  \n 3rd Qu.:3050.2   3rd Qu.:50.00   3rd Qu.:40.25                  \n Max.   :5606.6   Max.   :50.00   Max.   :50.00                  \n       WT               HT       \n Min.   : 56.60   Min.   :1.520  \n 1st Qu.: 73.17   1st Qu.:1.700  \n Median : 82.10   Median :1.770  \n Mean   : 82.55   Mean   :1.759  \n 3rd Qu.: 90.10   3rd Qu.:1.813  \n Max.   :115.30   Max.   :1.930  \n```\n:::\n:::\n\n\n## Data Processing\n\nIn this part, I want to recategorize Race Variables. Based on a paper provided in previous week, 1= White, 2= Black, 7= Native American, and 88= Others. In this execercise, 7 and 88 will be combined and label them \"3\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine RACE categories\ndata_ml <- data %>%\n  mutate(DOSE=as.numeric(as.character(DOSE))) %>%\n  mutate(SEX=as.numeric(as.character(SEX))) %>%\n  mutate(RACE=as.numeric(as.character(RACE))) %>%\n  mutate(RACE=case_when(RACE %in% c(7, 88) ~ 3,\n                        TRUE ~ RACE))\n```\n:::\n\n\n#Pairwise Correlations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create data for continous only for Pairwise \nPairwise_data <-  data_ml %>%\n  select(Y, AGE, WT, HT)\n\n#Create Correlation Plot for continus variables \n\nPairwise_data %>%\n  select(Y, AGE, WT, HT) %>%\n  ggpairs(\n    lower = list(continuous = wrap(\"points\", color = \"blue\", alpha = 0.6)),\n    diag = list(continuous = wrap(\"densityDiag\", fill = \"lightblue\", alpha = 0.5)),\n    upper = list(continuous = wrap(\"cor\", size = 4))\n  )\n```\n\n::: {.cell-output-display}\n![](ml-models-exercise_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nWeight is positively correlated with Height age, age is negatively correlated with height. However,all those variable have either very small correlation or moderate correlatio which is not a big concern for multicolinearity.\n\n#Featuring Engineering In this part, a new variable created for Body Mass Index (BMI) and creating histogram to visualize the BMI.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate BMI\ndata_ml <- data_ml %>%\n  mutate(BMI=WT/HT^2)\n\n#Create Histogram \nhist(data_ml$BMI)\n```\n\n::: {.cell-output-display}\n![](ml-models-exercise_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThe BMI looks distributted normally.\n\n# Model Building\n\nIn this exercise, I am going to create three models including Linear Regression, LASSO Regression, and Random Forest Model.\n\n### Linear Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Defining a linear model \nm1_lm_all <- linear_reg() %>% \n  set_engine(\"lm\") %>% \n  set_mode(\"regression\")\n\nm1_lm_all_wf <- workflow() %>% \n  add_model(m1_lm_all) %>% \n  add_formula(Y ~ .)\n\n# Fit models on the data\nlm_fit1 <- m1_lm_all_wf %>%\n  fit(data_ml)\n\n#compute prediction\n\npred_lm1 <- predict(lm_fit1, data_ml) %>% \n  bind_cols(data_ml)\n\n\n# calculate RMSE for the models\nrmse_lm1 <- rmse(pred_lm1, truth = Y, estimate = .pred) %>%\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        581.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot(pred_lm1, aes(x = .pred, y = Y)) +\n  geom_point(color = \"steelblue\", alpha = 0.7, size = 3) +  # Scatter points\n  geom_abline(slope = 1, intercept = 0, color = \"darkred\", linetype = \"dashed\", size = 1) +  # 1:1 reference line\n  labs(\n    title = \"Observed vs. Predicted Values: Linear Regression\",\n    x = \"Predicted Y\",\n    y = \"Observed Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    axis.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](ml-models-exercise_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n### LASSO Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(rngseed)\n\n#create lasso model\nm2_lasso1 <- linear_reg(penalty=.1) %>% set_engine(\"glmnet\")\n# create wok flow\nm2_lasso1_wf <- workflow() %>% \n  add_model(m2_lasso1) %>% \n  add_formula(Y ~ .)\n\n#fit model \nm2_lasso_fit <- m2_lasso1_wf %>% fit(data=data_ml)\n\n#compute prediction\n\npred_m2_lasso <- predict(m2_lasso_fit, data_ml) %>% \n  bind_cols(data_ml)\n\n\n# calculate RMSE for the models\nrmse_m2_lasso <- rmse(pred_m2_lasso, truth = Y, estimate = .pred) %>%\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        581.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pred_m2_lasso, aes(x = .pred, y = Y)) +\n  geom_point(color = \"darkgreen\", alpha = 0.7, size = 3) +  # Lasso prediction points\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\", size = 1) +  # Perfect prediction line\n  labs(\n    title = \"Observed vs. Predicted: Lasso Regression\",\n    x = \"Predicted Y\",\n    y = \"Observed Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    axis.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](ml-models-exercise_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### Random Forest Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(rngseed)\n\n#create Random Forest\nm3_rf1 <- rand_forest() %>% \n  set_engine(\"ranger\", seed= rngseed) %>%\n  set_mode(\"regression\")\n\n\n# create wok flow\nm3_rf1_wf <- workflow() %>% \n  add_model(m3_rf1) %>% \n  add_formula(Y ~ .)\n\n#fit model \nm3_rf1_fit <- m3_rf1_wf %>% fit(data=data_ml)\n\n#compute prediction\n\npred_m3_rf1 <- predict(m3_rf1_fit, data_ml) %>% \n  bind_cols(data_ml)\n\n\n# calculate RMSE for the models\nrmse_m3_rf1 <- rmse(pred_m3_rf1, truth = Y, estimate = .pred) %>%\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        362.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pred_m3_rf1, aes(x = .pred, y = Y)) +\n  geom_point(color = \"royalblue\", alpha = 0.7, size = 3) +  # Data points\n  geom_abline(slope = 1, intercept = 0, color = \"darkorange\", linetype = \"dashed\", size = 1) +  # Reference line\n  labs(\n    title = \"Observed vs. Predicted: Random Forest\",\n    x = \"Predicted Y\",\n    y = \"Observed Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    axis.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](ml-models-exercise_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nRandom Forest results the lowest RMSE (361.6) among three models, while RMSE the other two models is same (581.4)\n\n## Tunning the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create setseed\nset.seed(1234)\n\n#Create a tuning grid (50 values on log scale from 1e-5 to 1e2)\n\ngrid_lasso <- tibble(penalty=10^seq(-5, 2, length.out=50))\n\n# create tunning lasso\ntune_lasso <- linear_reg(penalty=tune()) %>% \n  set_engine(\"glmnet\")\n\n# create lasso work flow \nwf_lasso <- workflow() %>% add_model(tune_lasso) %>% \n  add_formula(Y ~ .)\n\n#  Tune the LASSO model\ntune_result_lasso <- wf_lasso %>% \n  tune_grid(resamples=apparent(data_ml), \n            grid=grid_lasso, metrics=metric_set(yardstick::rmse)) \n\n# create matric \nlasso_tune_result_metric <- as.data.frame(tune_result_lasso$.metrics)\n\n# Create plot\nggplot(lasso_tune_result_metric, aes(x=penalty, y=.estimate)) +\n  geom_line(linewidth=1, color=\"green\") +\n  scale_x_log10() +\n  labs(\n    x = \"Log penalty parameter\",\n    y = \"RMSE\",\n    title = \"Tuning Results for LASSO Model (RMSE vs Penalty)\"\n  ) +\n  theme_bw() +\n  theme(\n    axis.title.x = element_text(size = 10, color = \"black\", margin = margin(t = 15), face = \"bold\"),\n    axis.title.y = element_text(size = 10, color = \"black\", margin = margin(r = 15), face = \"bold\"),\n    axis.text.x = element_text(color = \"black\", size = 10, vjust = 0),\n    axis.text.y = element_text(color = \"black\", size = 10, hjust = 1), \n    legend.position = \"top\",\n    legend.title = element_text(size = 10), \n    legend.text = element_text(size = 10, vjust = 0)\n  )\n```\n\n::: {.cell-output-display}\n![](ml-models-exercise_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThe plot illustrates the tuning results of a LASSO regression model, showing how the root mean squared error (RMSE) varies across a range of penalty (λ) values on a logarithmic scale. As observed, RMSE remains relatively stable and low for smaller penalty values (approximately 10⁻⁵ to 10⁰), indicating good model performance. However, as the penalty increases beyond this range, RMSE rises sharply, suggesting that the model becomes overly regularized and loses predictive accuracy. This trend highlights the importance of selecting an optimal penalty value that balances model complexity and performance, with the best results occurring in the lower penalty region before the RMSE curve begins to escalate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed\nset.seed(1234)\n\n# Create tuning grid\ngrid_rf <- grid_regular(\n  mtry(range = c(1, ncol(data_ml) - 1)),  # exclude Y\n  min_n(range = c(2, 20)),\n  levels = 5\n)\n\n# Create tunable random forest model\ntune_rf <- rand_forest(mtry = tune(), min_n = tune()) %>%\n  set_engine(\"ranger\", seed = 1234) %>%\n  set_mode(\"regression\")\n\n# Create workflow\nwf_rf <- workflow() %>%\n  add_model(tune_rf) %>%\n  add_formula(Y ~ .)\n\n#  Tune the Random Forest model using apparent resample\ntune_result_rf <- wf_rf %>%\n  tune_grid(\n    resamples = apparent(data_ml),\n    grid = grid_rf,\n    metrics = metric_set(yardstick::rmse)\n  )\n\n# Convert tuning results to data frame\nrf_tune_result_metric <- as.data.frame(tune_result_rf$.metrics)\n\n\n# Use the correct RMSE column: .estimate\nrf_plot_df <- rf_tune_result_metric %>%\n  filter(.metric == \"rmse\")\n# create plot \nggplot(rf_tune_result_metric %>% filter(.metric == \"rmse\"), \n       aes(x = factor(mtry), y = factor(min_n), fill = .estimate)) +\n  geom_tile(color = \"white\") +\n  scale_fill_distiller(name = \"RMSE\", palette = \"Purples\", direction = 1) +\n  labs(\n    title = \"Random Forest Tuning Heatmap\",\n    x = \"mtry (Number of Predictors)\",\n    y = \"min_n (Minimum Node Size)\"\n  ) +\n  theme_bw() +\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\", hjust = 0.5, margin = margin(b = 10)),\n    axis.title.x = element_text(size = 16, color = \"black\", margin = margin(t = 15), face = \"bold\"),\n    axis.title.y = element_text(size = 16, color = \"black\", margin = margin(r = 15), face = \"bold\"),\n    axis.text.x = element_text(color = \"black\", size = 15),\n    axis.text.y = element_text(color = \"black\", size = 15),\n    legend.position = \"top\",\n    legend.title = element_text(size = 16),\n    legend.text = element_text(size = 12)\n  )\n```\n\n::: {.cell-output-display}\n![](ml-models-exercise_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nBased on the heatmap of RMSE values from the Random Forest tuning results, the lowest RMSE (i.e., best model performance) is observed in the bottom-right region of the plot --- specifically when both mtry is high (5--7) and min_n is small (2--6). This indicates that the model performs best when more predictors are considered at each split (mtry) and the minimum number of samples required to split a node is kept low (min_n). In contrast, model performance worsens (higher RMSE, darker purple) when min_n is large (15--20) and mtry is low (1--2), suggesting that overly simplified trees (due to aggressive pruning or limited variables) reduce predictive accuracy. Thus, tuning should prioritize larger mtry and smaller min_n values for optimal model performance in this case.\n\n# Tunning with Cross Validation (CV)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(rngseed)\n\n# 5-fold CV\ndata_cv <- vfold_cv(data_ml, v=5, repeats=5)\n\n# Workflow to tune the parameter\nlasso_tune_result_cv <- wf_lasso %>% \n  tune_grid(resamples=data_cv, grid=grid_lasso, metrics=metric_set(yardstick::rmse))\n\n# Make a plot of tuning results\nautoplot(lasso_tune_result_cv)\n```\n\n::: {.cell-output-display}\n![](ml-models-exercise_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nAs the amount of penalty parameter increase, the RMSE also increase.\n\nTunning the CB for Random Forest Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(rngseed)\n\n# Define the model specification using the ranger engine, with fixed trees at 300\nrf_cv <- rand_forest(\n  mode = \"regression\",\n  mtry = tune(),   \n  min_n = tune(), \n  trees = 300  \n) %>%\n  set_engine(\"ranger\", seed = rngseed)\n\n# Create a workflow\nrf_cv_wf <- workflow() %>%\n  add_model(rf_cv) %>%\n  add_formula(Y ~ .)\n\n\n# Perform tuning with tune_grid()\nrf_cv <- tune_grid(\n  rf_cv_wf,\n  resamples = vfold_cv(data_ml, v = 5, repeats = 5),\n  grid = grid_rf,\n  metrics = metric_set(rmse),\n  control = control_grid(save_pred = TRUE) \n)\n\nautoplot(rf_cv)\n```\n\n::: {.cell-output-display}\n![](ml-models-exercise_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "ml-models-exercise_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}